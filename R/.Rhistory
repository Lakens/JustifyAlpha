#' to be added
#' @importFrom stats optim pf pt
#' @export
#'
ttestEvidence <- function(evidence, n1, n2 = 0, one.sided = F, rscale = sqrt(2)/2) {
if (evidence == "lindley"){
evidence = 1
}
if (evidence == "moderate"){
evidence = 3
}
if (evidence == "strong"){
evidence = 10
}
if (n2 != 0){
df = n1 + n2 -2
}
else  {
df = n1 -1
}
crit_t <- optim(1.96, alpha_t.test_solve, lower = 0, upper = Inf, method = "L-BFGS-B",
n1 = n1, n2 = n2, evidence = evidence, rscale = rscale, one.sided = one.sided)$par
if (one.sided == F){
alpha <- (1 - pt(crit_t, df))*2
} else if(one.sided == T) {
alpha <- (1 - pt(crit_t, df))
}
return(alpha)
}
ttestEvidence(3, 20)
ttestEvidence(3, 20, one.sided = T)
ttestEvidence(20, 20, one.sided = T)
ttestEvidence(20, 2000, one.sided = T)
ttestEvidence(20, 10, one.sided = T)
ttestEvidence(20, 10, one.sided = F)
ttestEvidence(40, 10, one.sided = F)
ttestEvidence(40, 10, one.sided = T)
ttestEvidence(2, 10, one.sided = T)
ttestEvidence(2, 10, one.sided = F)
ttestEvidence(100000, 10, one.sided = F)
ttestEvidence(1000, 10, one.sided = F)
ttestEvidence(1000, 10, one.sided = T)
ttestEvidence(1, 10, one.sided = T)
ttestEvidence(1, 10, one.sided = F)
ttestEvidence(1, 100, one.sided = F)
ttestEvidence(1, 100, one.sided = T)
?t.test
bf_t.test <- function(t, n1, n2 = 0, rscale = sqrt(2)/2, alternative = F){
# if (n2 == 0) {
#   v <- n1 -1
#   N <- n1
# } else {
#   N <- n1*n2/(n1+n2)
#   v <- n1 + n2 -2
# }
# if (Cauchy == F) {
#   ml1 <- 1/sqrt(1+N)*(1+t^2/((1+N)*v))^(-(v+1)/2)
#   ml0 <- (1+t^2/v)^(-(v+1)/2)
#   return(ml1/ml0)
# } else {
if(alternative == "two.sided"){
return(exp(BayesFactor::ttest.tstat(t, n1, n2, rscale = rscale)$bf))
}
else if(alternative == "greater"){
return(exp(BayesFactor::ttest.tstat(t, n1, n2, rscale = rscale, nullInterval = c(0, Inf))$bf))
}
else if(alternative == "less"){
return(exp(BayesFactor::ttest.tstat(t, n1, n2, rscale = rscale, nullInterval = c(-Inf, 0))$bf))
}
}
alpha_t.test_solve <- function(x, n1, n2, evidence, rscale, alternative){
(evidence - bf_t.test(x, n1, n2, rscale, alternative))^2
}
#' @param rscale Scale of the Cauchy prior distribution.
#' @return alpha level required for a two-sample t-test.
#' @examples
#' ## Avoid the Lindley paradox for a two sample t-test with 300 participants per condition
#' ttestEvidence("lindley", 300, 300)
#' @section References:
#' to be added
#' @importFrom stats optim pf pt
#' @export
#'
ttestEvidence <- function(evidence, n1, n2 = 0, alternative = c("two.sided", "less", "greater"), rscale = sqrt(2)/2) {
if (evidence == "lindley"){
evidence = 1
}
if (evidence == "moderate"){
evidence = 3
}
if (evidence == "strong"){
evidence = 10
}
if (n2 != 0){
df = n1 + n2 -2
}
else  {
df = n1 -1
}
crit_t <- optim(1.96, alpha_t.test_solve, lower = 0, upper = Inf, method = "L-BFGS-B",
n1 = n1, n2 = n2, evidence = evidence, rscale = rscale, alternative = alternative)$par
if (alternative == "two.sided"){
alpha <- (1 - pt(crit_t, df))*2
} else if(alternative == "greater") {
alpha <- (1 - pt(crit_t, df))
} else if(alternative == "less"){
alpha <- pt(crit_t, df))
}
return(alpha)
}
#' @param rscale Scale of the Cauchy prior distribution.
#' @return alpha level required for a two-sample t-test.
#' @examples
#' ## Avoid the Lindley paradox for a two sample t-test with 300 participants per condition
#' ttestEvidence("lindley", 300, 300)
#' @section References:
#' to be added
#' @importFrom stats optim pf pt
#' @export
#'
ttestEvidence <- function(evidence, n1, n2 = 0, alternative = c("two.sided", "less", "greater"), rscale = sqrt(2)/2) {
if (evidence == "lindley"){
evidence = 1
}
if (evidence == "moderate"){
evidence = 3
}
if (evidence == "strong"){
evidence = 10
}
if (n2 != 0){
df = n1 + n2 -2
}
else  {
df = n1 -1
}
crit_t <- optim(1.96, alpha_t.test_solve, lower = 0, upper = Inf, method = "L-BFGS-B",
n1 = n1, n2 = n2, evidence = evidence, rscale = rscale, alternative = alternative)$par
if (alternative == "two.sided"){
alpha <- (1 - pt(crit_t, df))*2
} else if(alternative == "greater") {
alpha <- (1 - pt(crit_t, df))
} else if(alternative == "less"){
alpha <- pt(crit_t, df)
}
return(alpha)
}
ttestEvidence(3, 20)
warnings()
bf_t.test <- function(t, n1, n2 = 0, rscale = sqrt(2)/2, alternative = F){
# if (n2 == 0) {
#   v <- n1 -1
#   N <- n1
# } else {
#   N <- n1*n2/(n1+n2)
#   v <- n1 + n2 -2
# }
# if (Cauchy == F) {
#   ml1 <- 1/sqrt(1+N)*(1+t^2/((1+N)*v))^(-(v+1)/2)
#   ml0 <- (1+t^2/v)^(-(v+1)/2)
#   return(ml1/ml0)
# } else {
if(alternative == "two.sided"){
return(exp(BayesFactor::ttest.tstat(t, n1, n2, rscale = rscale)$bf))
}
else if(alternative == "greater"){
return(exp(BayesFactor::ttest.tstat(t, n1, n2, rscale = rscale, nullInterval = c(0, Inf))$bf))
}
else if(alternative == "less"){
return(exp(BayesFactor::ttest.tstat(t, n1, n2, rscale = rscale, nullInterval = c(-Inf, 0))$bf))
}
}
alpha_t.test_solve <- function(x, n1, n2, evidence, rscale, alternative){
(evidence - bf_t.test(x, n1, n2, rscale, alternative))^2
}
#' @param rscale Scale of the Cauchy prior distribution.
#' @return alpha level required for a two-sample t-test.
#' @examples
#' ## Avoid the Lindley paradox for a two sample t-test with 300 participants per condition
#' ttestEvidence("lindley", 300, 300)
#' @section References:
#' to be added
#' @importFrom stats optim pf pt
#' @export
#'
ttestEvidence <- function(evidence, n1, n2 = 0, alternative = "two.sided" , rscale = sqrt(2)/2) {
if (evidence == "lindley"){
evidence = 1
}
if (evidence == "moderate"){
evidence = 3
}
if (evidence == "strong"){
evidence = 10
}
if (n2 != 0){
df = n1 + n2 -2
}
else  {
df = n1 -1
}
crit_t <- optim(1.96, alpha_t.test_solve, lower = 0, upper = Inf, method = "L-BFGS-B",
n1 = n1, n2 = n2, evidence = evidence, rscale = rscale, alternative = alternative)$par
if (alternative == "two.sided"){
alpha <- (1 - pt(crit_t, df))*2
} else if(alternative == "greater") {
alpha <- (1 - pt(crit_t, df))
} else if(alternative == "less"){
alpha <- pt(crit_t, df)
} else {
stop("Alternative must be 'two.sided', 'less', or 'greater'")
}
return(alpha)
}
ttestEvidence(3, 20)
ttestEvidence(3, 20, alternative = "greater")
ttestEvidence(3, 20, alternative = "less")
bf_t.test <- function(t, n1, n2 = 0, rscale = sqrt(2)/2, one.sided = F){
# if (n2 == 0) {
#   v <- n1 -1
#   N <- n1
# } else {
#   N <- n1*n2/(n1+n2)
#   v <- n1 + n2 -2
# }
# if (Cauchy == F) {
#   ml1 <- 1/sqrt(1+N)*(1+t^2/((1+N)*v))^(-(v+1)/2)
#   ml0 <- (1+t^2/v)^(-(v+1)/2)
#   return(ml1/ml0)
# } else {
if(one.sided == F){
return(exp(BayesFactor::ttest.tstat(t, n1, n2, rscale = rscale)$bf))
}
else if(one.sided == T){
return(exp(BayesFactor::ttest.tstat(t, n1, n2, rscale = rscale, nullInterval = c(0, Inf))$bf))
}
}
alpha_t.test_solve <- function(x, n1, n2, evidence, rscale, one.sided){
(evidence - bf_t.test(x, n1, n2, rscale, one.sided))^2
}
#' @param rscale Scale of the Cauchy prior
#' @return alpha level required for a two-sample t-test.
#' @examples
#' ## Avoid the Lindley paradox for a two sample t-test with 300 participants per condition
#' ttestEvidence("lindley", 300, 300)
#' @section References:
#' to be added
#' @importFrom stats optim pf pt
#' @export
#'
ttestEvidence <- function(evidence, n1, n2 = 0, one.sided = F, rscale = sqrt(2)/2) {
if (evidence == "lindley"){
evidence = 1
}
if (evidence == "moderate"){
evidence = 3
}
if (evidence == "strong"){
evidence = 10
}
if (n2 != 0){
df = n1 + n2 -2
}
else  {
df = n1 -1
}
crit_t <- optim(1.96, alpha_t.test_solve, lower = 0, upper = Inf, method = "L-BFGS-B",
n1 = n1, n2 = n2, evidence = evidence, rscale = rscale, one.sided = one.sided)$par
if (one.sided == F){
alpha <- (1 - pt(crit_t, df))*2
} else if(one.sided == T) {
alpha <- (1 - pt(crit_t, df))
}
return(alpha)
}
ttestEvidence(10, 20)
ttestEvidence(10, 20, one.sided = T)
ttestEvidence(1, 20, one.sided = T)
ttestEvidence(1, 20, one.sided = F)
devtools::build()
setwd("C:/Users/Maximilian Maier/Desktop/PaperWriting/IdealAlpha/JustifieR/R")
devtools::build()
devtools::document()
devtools::build()
devtools::check()
?optimal_sample
optimal_sample_Anova(n){
design_result <- Superpower::ANOVA_design(
design = "2b",
n = n,
mu = c(0, 0.5),
sd = 1
)
Superpower::power_oneway_between(design_result, alpha_level = x)$power/100
}
res$optimal_sample("optimal_sample_Anova(n = sample_n)")
res7$samplesize
res7$alpha
res7$beta
res7$errorrate
optimal_sample_Anova(n){
design_result <- Superpower::ANOVA_design(
design = "2b",
n = n,
mu = c(0, 0.5),
sd = 1
)
Superpower::power_oneway_between(design_result, alpha_level = x)$power/100
}
res <- optimal_sample("optimal_sample_Anova(n = sample_n)")
res$samplesize
res$alpha
res$beta
res$errorrate
optimal_sample_Anova <- function(n){
design_result <- Superpower::ANOVA_design(
design = "2b",
n = n,
mu = c(0, 0.5),
sd = 1
)
Superpower::power_oneway_between(design_result, alpha_level = x)$power/100
}
res <- optimal_sample("optimal_sample_Anova(n = sample_n)")
res$samplesize
res$alpha
res$beta
res$errorrate
optimal_sample_Anova <- function(x, n){
design_result <- Superpower::ANOVA_design(
design = "2b",
n = n,
mu = c(0, 0.5),
sd = 1
)
Superpower::power_oneway_between(design_result, alpha_level = x)$power/100
}
res8 <- optimal_sample("optimal_sample_Anova(x, n = sample_n)")
bf_t.test <- function(t, n1, n2 = 0, rscale = sqrt(2)/2, one.sided = F){
# if (n2 == 0) {
#   v <- n1 -1
#   N <- n1
# } else {
#   N <- n1*n2/(n1+n2)
#   v <- n1 + n2 -2
# }
# if (Cauchy == F) {
#   ml1 <- 1/sqrt(1+N)*(1+t^2/((1+N)*v))^(-(v+1)/2)
#   ml0 <- (1+t^2/v)^(-(v+1)/2)
#   return(ml1/ml0)
# } else {
if(!one.sided){
return(exp(BayesFactor::ttest.tstat(t, n1, n2, rscale = rscale)$bf))
}
else if(one.sided){
return(exp(BayesFactor::ttest.tstat(t, n1, n2, rscale = rscale, nullInterval = c(0, Inf))$bf))
}
}
alpha_t.test_solve <- function(x, n1, n2, evidence, rscale, one.sided){
(evidence - bf_t.test(x, n1, n2, rscale, one.sided))^2
}
#' @param rscale Scale of the Cauchy prior
#' @return alpha level required for a two-sample t-test.
#' @examples
#' ## Avoid the Lindley paradox for a two sample t-test with 300 participants per condition
#' ttestEvidence("lindley", 300, 300)
#' @section References:
#' to be added
#' @importFrom stats optim pf pt
#' @export
#'
ttestEvidence <- function(evidence, n1, n2 = 0, one.sided = F, rscale = sqrt(2)/2) {
if (evidence == "lindley"){
evidence = 1
}
if (evidence == "moderate"){
evidence = 3
}
if (evidence == "strong"){
evidence = 10
}
if (n2 != 0){
df = n1 + n2 -2
}
else  {
df = n1 -1
}
crit_t <- optim(1.96, alpha_t.test_solve, lower = 0, upper = Inf, method = "L-BFGS-B",
n1 = n1, n2 = n2, evidence = evidence, rscale = rscale, one.sided = one.sided)$par
if (!one.sided){
alpha <- (1 - pt(crit_t, df))*2
} else if(one.sided) {
alpha <- (1 - pt(crit_t, df))
}
return(alpha)
}
bf_bic <- function(F, df1, df2, repeated=FALSE, report.as="BF10") {
if (repeated==FALSE) {
N = df1+df2+1
}
else {
N = df1+df2
}
bf = sqrt(N^df1*(1+F*df1/df2)^(-1*N))
if (report.as=="BF01"){
return(c(B01=bf))
}
else {
return(c(B10=1/bf))
}
}
alpha_f.test_solve <- function(x, df1, df2, evidence, paired){
(evidence - bf_bic(x, df1, df2, paired))^2
}
ttestEvidence(3, 10)
ttestEvidence(3, 10, one.sided = T)
res <- BayesFactor::ttest.tstat(2, 20, rscale = 0.707, nullInterval = c(0, Inf))
res
n1 <- 150
loops <- seq(from = 0, to = 7, by = 0.001)
p <- numeric(length(loops))
bf <- numeric(length(loops))
#d <- numeric(length(loops))
tval <- numeric(length(loops))
i <- 0
for(t in loops){
i <- i+1
bf[i] <- exp(BayesFactor::ttest.tstat(t, n1, rscale = 0.707, nullInterval = c(0, Inf))$bf)
p[i] <- 2*pt(t, ((n1) - 1), lower=FALSE)
tval[i] <- t
#d[i] <- t * sqrt((1/n1)+(1/n2))
}
lindley  <- ttestEvidence(1,  150, one.sided = TRUE)
moderate <- ttestEvidence(3,  150, one.sided = TRUE)
strong   <- ttestEvidence(10, 150, one.sided = TRUE)
lindley
moderate
strong
plot(p, bf, type="l", lty=1, lwd=3, xlim = c(0, 0.05), ylim = c(0, 10), axes = F, xlab = "p-value", ylab = "Bayes factor")
axis(side=1, at = c(0, as.numeric(lindley), as.numeric(moderate), as.numeric(strong), 0.05), labels = c(0, round(lindley, digits = 3), round(moderate, digits = 3), round(strong, digits = 3), 0.05),  lwd = 3, las = 3)
axis(side=2, at = c(0.33, 1, 3, 10), labels = c("1/3", 1, 3, 10), lwd = 3)
abline(h = c(1, 3, 10), col = "gray", lty = 2)
abline(v = c(lindley, moderate, strong), lty = 3)
sqrt(2, 2)
sqrt(2)/2
lindley  <- ttestEvidence(1,  150, one.sided = TRUE, rscale = 0.707)
moderate <- ttestEvidence(3,  150, one.sided = TRUE, rscale = 0.707)
strong   <- ttestEvidence(10, 150, one.sided = TRUE, rscale = 0.707)
plot(p, bf, type="l", lty=1, lwd=3, xlim = c(0, 0.05), ylim = c(0, 10), axes = F, xlab = "p-value", ylab = "Bayes factor")
axis(side=1, at = c(0, as.numeric(lindley), as.numeric(moderate), as.numeric(strong), 0.05), labels = c(0, round(lindley, digits = 3), round(moderate, digits = 3), round(strong, digits = 3), 0.05),  lwd = 3, las = 3)
axis(side=2, at = c(0.33, 1, 3, 10), labels = c("1/3", 1, 3, 10), lwd = 3)
abline(h = c(1, 3, 10), col = "gray", lty = 2)
abline(v = c(lindley, moderate, strong), lty = 3)
n1 <- 150
loops <- seq(from = 0, to = 7, by = 0.001)
p <- numeric(length(loops))
bf <- numeric(length(loops))
#d <- numeric(length(loops))
tval <- numeric(length(loops))
i <- 0
for(t in loops){
i <- i+1
bf[i] <- exp(BayesFactor::ttest.tstat(t, n1, rscale = 0.707, nullInterval = c(0, Inf))$bf)
p[i] <- pt(t, ((n1) - 1), lower=FALSE)
tval[i] <- t
#d[i] <- t * sqrt((1/n1)+(1/n2))
}
lindley  <- ttestEvidence(1,  150, one.sided = TRUE, rscale = 0.707)
moderate <- ttestEvidence(3,  150, one.sided = TRUE, rscale = 0.707)
strong   <- ttestEvidence(10, 150, one.sided = TRUE, rscale = 0.707)
plot(p, bf, type="l", lty=1, lwd=3, xlim = c(0, 0.05), ylim = c(0, 10), axes = F, xlab = "p-value", ylab = "Bayes factor")
axis(side=1, at = c(0, as.numeric(lindley), as.numeric(moderate), as.numeric(strong), 0.05), labels = c(0, round(lindley, digits = 3), round(moderate, digits = 3), round(strong, digits = 3), 0.05),  lwd = 3, las = 3)
axis(side=2, at = c(0.33, 1, 3, 10), labels = c("1/3", 1, 3, 10), lwd = 3)
abline(h = c(1, 3, 10), col = "gray", lty = 2)
abline(v = c(lindley, moderate, strong), lty = 3)
lindley
moderate
strong
design_result <- Superpower::ANOVA_design(
design = "2b",
n = 64,
mu = c(0, 0.5),
sd = 1
)
Superpower::ANOVA_exact(design_result, alpha_level = 0.05, verbose = FALSE)$main_results$power/100
Superpower::power_oneway_between(design_result, alpha_level = 0.05)$power/100
pwr.t.test(d=0.5, n=64, sig.level = 0.05, type='two.sample', alternative='two.sided')$power
res7 <- justifieR::optimal_alpha(power_function = "Superpower::power_oneway_between(design_result, alpha_level = x)$power/100",
error = "minimal",
costT1T2 = 1,
priorH1H0 = 1)
res7$alpha
res7$beta
res7$errorrate
optimal_sample_Anova <- function(x, n){
design_result <- Superpower::ANOVA_design(
design = "2b",
n = n,
mu = c(0, 0.5),
sd = 1
)
Superpower::power_oneway_between(design_result, alpha_level = x)$power/100
}
res8 <- optimal_sample("optimal_sample_Anova(x, n = sample_n)")
res8$samplesize
res8$alpha
res8$beta
res8$errorrate
install_github("Lakens/justifieR")
devtools::install_github("Lakens/justifieR")
library(justifieR)
?ttestEvidence
